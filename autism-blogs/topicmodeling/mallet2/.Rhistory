line <- readline()
plot1 <- ggplot() +
geom_line(data = df.results, size = 2, aes(x = year, y = rice, group=1, color = "Actual Values")) +
geom_line(data = df.results, size = 2, aes(x = year, y = rice_pred, group=1, color = "Predicted")) +
geom_line(data = df.results, size = 2, aes(x = year, y = rice_diff, group=1, color = "Difference")) +
xlab("Year") +
ylab("Tonnes per Hectare) +
ggtitle("Rice Actual vs. Prediction")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Actual Oilseed Values vs. our model prediction.")
cat("\n")
line <- readline()
plot1 <- ggplot() +
geom_line(data = df.results, size = 2, aes(x = year, y = oilseed, group=1, color = "Actual Values")) +
geom_line(data = df.results, size = 2, aes(x = year, y = oilseed_pred, group=1, color = "Predicted")) +
geom_line(data = df.results, size = 2, aes(x = year, y = oilseed_diff, group=1, color = "Difference")) +
xlab("Year) +
ylab("Tonnes per Hectare") +
ggtitle("Oilseed Actual vs. Prediction")
print(plot1)
# CSE 198 final project
# Yin Luo, Jon Ross, Tobin Dewey, Keith Knapp
# load data from the files
weatherraw <- read.table("USweather.txt", header = T)
cropraw <- read.csv("cropoutput.csv")
weathernew <- weatherraw
weathernew <- weathernew[,c ("YearMonth", "TAVG", "PCP", "PDSI", "PHDI", "ZNDX", "PMDI", "CDD", "HDD", "TMIN", "TMAX")]
# filter out unused data in the data set, TONNE_HA means Tonnes/hectare
weatherraw <- weatherraw[,c("YearMonth", "TAVG", "PCP")]
cropraw <- cropraw[grepl("USA", cropraw$LOCATION) & grepl("TONNE_HA", cropraw$MEASURE)==T,c("SUBJECT", "TIME", "Value")]
# construct a new data frame that holds the average temperature and precipitation
# for a whole year
weatheryear <- data.frame()
for(i in 1:(nrow(weatherraw)/12)) {
sumt = 0
sump = 0
for(j in 1:12) {
sumt = sumt + weatherraw[(i-1)*12+j, "TAVG"]
sump = sump + weatherraw[(i-1)*12+j, "PCP"]
}
weatheryear <- rbind(weatheryear,data.frame(year=substr(weatherraw[(i-1)*12+1, "YearMonth"], 1, 4),
temp_avg=sumt/12, pcp_avg=sump/12))
}
#Buiding weathermodel df which includes more of the weather data. Takes the averages over the months to mesh with cropdata.
weathermodel <- data.frame()
for(i in 1:(nrow(weathernew)/12)) {
sumtemp = 0
sumpcp = 0
sumpdsi = 0
sumphdi = 0
sumzndx = 0
sumpmdi = 0
sumcdd = 0
sumhdd = 0
sumtmin = 0
sumtmax = 0
for(j in 1:12) {
sumtemp = sumtemp + weathernew[(i-1)*12+j, "TAVG"]
sumpcp = sumpcp + weathernew[(i-1)*12+j, "PCP"]
sumpdsi = sumpdsi + weathernew[(i-1)*12+j, "PDSI"]
sumphdi = sumphdi + weathernew[(i-1)*12+j, "PHDI"]
sumzndx = sumzndx + weathernew[(i-1)*12+j, "ZNDX"]
sumpmdi = sumpmdi + weathernew[(i-1)*12+j, "PMDI"]
sumcdd = sumcdd + weathernew[(i-1)*12+j, "CDD"]
sumhdd = sumhdd + weathernew[(i-1)*12+j, "HDD"]
sumtmin = sumtmin + weathernew[(i-1)*12+j, "TMIN"]
sumtmax = sumtmax + weathernew[(i-1)*12+j, "TMAX"]
}
weathermodel <- rbind(weathermodel,data.frame(year=substr(weathernew[(i-1)*12+1, "YearMonth"], 1, 4),
temp_avg=sumtemp/12, pcp_avg=sumpcp/12, pdsi_avg=sumpdsi/12, phdi_avg=sumphdi/12, zndx_avg=sumzndx/12, pmdi_avg=sumpmdi/12, cdd_avg=sumcdd/12, hdd_avg=sumhdd/12, tmin_avg=sumtmin/12, tmax_avg=sumtmax/12))
}
# cleaning the data
weatheryear$year <- strtoi(weatheryear$year)
weatheryear$temp_avg <- round(weatheryear$temp_avg, digit=2)
weatheryear$pcp_avg <- round(weatheryear$pcp_avg, digit=2)
# constuct a new data frame that holds value of each crop in a single role by their year
cropyear <- data.frame()
for(i in 1970:2015) {
j <- cropraw[grepl(i, cropraw$TIME)==TRUE,]
cropyear <- rbind(cropyear, data.frame(year=i, wheat=j[grepl("WHEAT", j$SUBJECT)==T, "Value"],
grain=j[grepl("COARSGRAIN", j$SUBJECT)==T, "Value"],
rice=j[grepl("RICE", j$SUBJECT)==T, "Value"],
oilseed=j[grepl("OILSEED", j$SUBJECT)==T, "Value"]))
}
# new data frame for organizing crops by their type
croptype <- data.frame()
for(i in 1:nrow(cropyear)){
croptype <- rbind(croptype, data.frame(year=cropyear[i,"year"], value=cropyear[i,"wheat"],type="wheat", temp=weatheryear[i,"temp_avg"]))
croptype <- rbind(croptype, data.frame(year=cropyear[i,"year"], value=cropyear[i,"grain"],type="grain", temp=weatheryear[i,"temp_avg"]))
croptype <- rbind(croptype, data.frame(year=cropyear[i,"year"], value=cropyear[i,"rice"],type="rice", temp=weatheryear[i,"temp_avg"]))
croptype <- rbind(croptype, data.frame(year=cropyear[i,"year"], value=cropyear[i,"oilseed"],type="oilseed", temp=weatheryear[i,"temp_avg"]))
}
#print(croptype)
# merge the two data frames into one data frame, joined on the year variable.
df<-data.frame()
df<-merge(weatheryear,cropyear)
dfmodel<-data.frame()
dfmodel<-merge(weathermodel,cropyear)
library("ggplot2")
plot1 <- qplot(data=df, x=year, y=temp_avg, xlab="Year", ylab="Average Temperature", main="Temperature over Time") +
stat_smooth(method="lm") + geom_point(colour="red")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Precipitation over time.")
cat("\n")
line <- readline()
plot1 <- qplot(data=df, x=year, y=pcp_avg, xlab="Year", ylab="Average Precipitation", main="Precipitation over Time") +
stat_smooth(method="lm") + geom_point(colour="blue")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Wheat Growth over time.")
cat("\n")
line <- readline()
plot1 <- qplot(data=df, x=year, y=wheat, xlab="Year", ylab="Wheat Growth", main="Wheat Growth over Time") +
stat_smooth(method="lm") + geom_point(colour="gold")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Grain Growth over time.")
cat("\n")
line <- readline()
plot1 <- qplot(data=df, x=year, y=grain, xlab="Year", ylab="Grain Growth", main="Grain Growth over Time") +
stat_smooth(method="lm") + geom_point(colour="black")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Rice Growth over time.")
cat("\n")
line <- readline()
plot1 <- qplot(data=df, x=year, y=rice, xlab="Year", ylab="Rice Growth", main="Rice Growth over Time") +
stat_smooth(method="lm") + geom_point(colour="green")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Oilseed Growth over time.")
cat("\n")
line <- readline()
plot1 <- qplot(data=df, x=year, y=oilseed, xlab="Year", ylab="Oilseed Growth", main="Oilseed Growth over Time") +
stat_smooth(method="lm") + geom_point(colour="purple")
print(plot1)
cat("\n")
cat ("Please press [enter] to see a combined graph.")
cat("\n")
line <- readline()
plot1 <- qplot(data=croptype, x=year, y=value, color=type, xlab="Year", ylab="Value", main="Attributes Over Time")
print(plot1)
cat("\n")
cat ("Please press [enter] to see crop production vs temperature.")
cat("\n")
line <- readline()
plot1 <- qplot(data=croptype, x=temp, y= value, color=type, xlab="Temperature", ylab="Crop Production", main="Crop production vs Temperature")
print(plot1)
###############################################################################
set.seed(1492) #An important year, and as good as any for a seed value.
#split into training and testing
m<-dim(dfmodel)[1]
val<-sample(1:m, size=round(m/3), replace=FALSE, prob=rep(1/m,m))
df.test<-dfmodel[val,]
df.train<-dfmodel[-val,]
#2/3 for training, 1/3 for testing because we do not have very many instances (45)
#print(df.model.train)
#print(df.model.test)
#Building linear models using training set. One model per crop. Other crops and year are excluded from consideration.
df.train.w.mlr <- lm(wheat ~ temp_avg + pcp_avg + pdsi_avg + phdi_avg + zndx_avg + pmdi_avg + cdd_avg + hdd_avg + tmin_avg + tmax_avg, data=df.train)
df.train.g.mlr <- lm(grain ~ temp_avg + pcp_avg + pdsi_avg + phdi_avg + zndx_avg + pmdi_avg + cdd_avg + hdd_avg + tmin_avg + tmax_avg, data=df.train)
df.train.r.mlr <- lm(rice ~ temp_avg + pcp_avg + pdsi_avg + phdi_avg + zndx_avg + pmdi_avg + cdd_avg + hdd_avg + tmin_avg + tmax_avg, data=df.train)
df.train.o.mlr <- lm(oilseed ~ temp_avg + pcp_avg + pdsi_avg + phdi_avg + zndx_avg + pmdi_avg + cdd_avg + hdd_avg + tmin_avg + tmax_avg, data=df.train)
#Predictions are made for each model on the testset.
predw <- predict.lm(df.train.w.mlr, df.test)
predg <- predict.lm(df.train.g.mlr, df.test)
predr <- predict.lm(df.train.r.mlr, df.test)
predo <- predict.lm(df.train.o.mlr, df.test)
#Predictions coerced into dataframes.
predw <- as.data.frame(predw)
predg <- as.data.frame(predg)
predr <- as.data.frame(predr)
predo <- as.data.frame(predo)
#Given column names.
colnames(predw) <- c("wheat_pred")
colnames(predg) <- c("grain_pred")
colnames(predr) <- c("rice_pred")
colnames(predo) <- c("oilseed_pred")
#Each of the predictions are binded to the testset so that actual values and predictions can be more easily compared.
df.test <- cbind(df.test,predw)
df.test <- cbind(df.test,predg)
df.test <- cbind(df.test,predr)
df.test <- cbind(df.test,predo)
#The absolute value of differences between actual values and predictions are calculated.
df.test$wheat_diff <- abs(df.test$wheat_pred - df.test$wheat)
df.test$grain_diff <- abs(df.test$grain_pred - df.test$grain)
df.test$rice_diff <- abs(df.test$rice_pred - df.test$rice)
df.test$oilseed_diff <- abs(df.test$oilseed_pred - df.test$oilseed)
#New dataframe created with only the necessary data.
df.results <- df.test[-(2:11)]
print(df.results)
cat("\n")
cat ("Please press [enter] to see Actual Wheat Values vs. our model prediction.")
cat("\n")
line <- readline()
#A series of plots are created and displayed which compare the actual values and the predicted values for each crop.
#The difference is also shown to give an idea of the accuracy of the predictions.
plot1 <- ggplot() +
geom_line(data = df.results, size = 2, aes(x = year, y = wheat, group=1, color = "Actual Values")) +
geom_line(data = df.results, size = 2, aes(x = year, y = wheat_pred, group=1, color = "Predicted")) +
geom_line(data = df.results, size = 2, aes(x = year, y = wheat_diff, group=1, color = "Difference")) +
xlab('Year') +
ylab('Tonnes per Hectare') +
ggtitle("Wheat Actual vs. Prediction")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Actual Grain Values vs. our model prediction.")
cat("\n")
line <- readline()
plot1 <- ggplot() +
geom_line(data = df.results, size = 2, aes(x = year, y = grain, group=1, color = "Actual Values")) +
geom_line(data = df.results, size = 2, aes(x = year, y = grain_pred, group=1, color = "Predicted")) +
geom_line(data = df.results, size = 2, aes(x = year, y = grain_diff, group=1, color = "Difference")) +
xlab("Year") +
ylab("Tonnes per Hectare") +
ggtitle("Grain Actual vs. Prediction")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Actual Rice Values vs. our model prediction.")
cat("\n")
line <- readline()
plot1 <- ggplot() +
geom_line(data = df.results, size = 2, aes(x = year, y = rice, group=1, color = "Actual Values")) +
geom_line(data = df.results, size = 2, aes(x = year, y = rice_pred, group=1, color = "Predicted")) +
geom_line(data = df.results, size = 2, aes(x = year, y = rice_diff, group=1, color = "Difference")) +
xlab("Year") +
ylab("Tonnes per Hectare") +
ggtitle("Rice Actual vs. Prediction")
print(plot1)
cat("\n")
cat ("Please press [enter] to see Actual Oilseed Values vs. our model prediction.")
cat("\n")
line <- readline()
plot1 <- ggplot() +
geom_line(data = df.results, size = 2, aes(x = year, y = oilseed, group=1, color = "Actual Values")) +
geom_line(data = df.results, size = 2, aes(x = year, y = oilseed_pred, group=1, color = "Predicted")) +
geom_line(data = df.results, size = 2, aes(x = year, y = oilseed_diff, group=1, color = "Difference")) +
xlab("Year") +
ylab("Tonnes per Hectare") +
ggtitle("Oilseed Actual vs. Prediction")
print(plot1)
library(dplyr)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library(ggplot2)
library(reshape2)
library(jsonlite)
install.packages(dplyr)
install.packages("dplyr")
install.packages("rJava")
install.packages("mallet")
install.packages("ggplot2")
install.packages("jsonlite")
library(dplyr)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library(ggplot2)
library(reshape2)
library(jsonlite)
install.packages("rJava")
install.packages("reshape2")
#Import necessary libraries
library(dplyr)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library(ggplot2)
library(reshape2)
library(jsonlite)
#Set number of topics
n.topics <- 50
#Set working directory
#setwd("/Users/jatinbharwani/Desktop/Summer16/Research/mallet2")
#Import Json file to a data variable (requires formatting data once imported)
json_file <- "merged_file.json"
data <- fromJSON(json_file)
data <- bind_rows(data, .id = 'blog')
#Use rbind to create a documents variable from the data.frame
documents <- rbind(data.frame(blogid=data$blog, link=data$link, title=data$title, text=data$body,  stringsAsFactors=F))
#Use mallet as in sample code
mallet.instances <- mallet.import(documents$title, documents$text, "blog.stop", token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")
## Create a topic trainer object.
topic.model <- MalletLDA(num.topics=n.topics)
## Load our documents. We could also pass in the filename of a
##  saved instance list file that we build from the command-line tools.
topic.model$loadDocuments(mallet.instances)
## Get the vocabulary, and some statistics about word frequencies.
#vocabulary <- topic.model$getVocabulary()
#word.freqs <- mallet.word.freqs(topic.model)
## Optimize hyperparameters every 20 iterations,
##  after 50 burn-in iterations.
topic.model$setAlphaOptimization(20, 50)
## Now train a model.
##  We can specify the number of iterations. Here we'll use a large-ish round number.
topic.model$train(1000)
topic.model$maximize(50)
doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
topic.words <- mallet.topic.words(topic.model, smoothed=T, normalized=T)
mallet.top.words(topic.model, topic.words[1,], 30)
topics.labels <- gsub("\\W", "_", mallet.topic.labels(topic.model, topic.words, 3))
topics.long.labels <- mallet.topic.labels(topic.model, topic.words, num.top.words=50)
doc.topics.frame <- data.frame(doc.topics)
#names(doc.topics.frame) <- paste("Topic", 1:n.topics, sep="")
names(doc.topics.frame) <- topics.labels
docs.and.topics <- cbind(documents, doc.topics.frame)
library (rJava)
install.packages('rJava', .libPaths()[1], 'http://www.rforge.net/')
library(dplyr)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
#Import necessary libraries
library(dplyr)
library (rJava)
#.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library(ggplot2)
library(reshape2)
library(jsonlite)
#Set number of topics
n.topics <- 50
#Set working directory
#setwd("/Users/jatinbharwani/Desktop/Summer16/Research/mallet2")
#Import Json file to a data variable (requires formatting data once imported)
json_file <- "merged_file.json"
data <- fromJSON(json_file)
data <- bind_rows(data, .id = 'blog')
#Use rbind to create a documents variable from the data.frame
documents <- rbind(data.frame(blogid=data$blog, link=data$link, title=data$title, text=data$body,  stringsAsFactors=F))
#Use mallet as in sample code
mallet.instances <- mallet.import(documents$title, documents$text, "blog.stop", token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")
## Create a topic trainer object.
topic.model <- MalletLDA(num.topics=n.topics)
## Load our documents. We could also pass in the filename of a
##  saved instance list file that we build from the command-line tools.
topic.model$loadDocuments(mallet.instances)
## Get the vocabulary, and some statistics about word frequencies.
#vocabulary <- topic.model$getVocabulary()
#word.freqs <- mallet.word.freqs(topic.model)
## Optimize hyperparameters every 20 iterations,
##  after 50 burn-in iterations.
topic.model$setAlphaOptimization(20, 50)
## Now train a model.
##  We can specify the number of iterations. Here we'll use a large-ish round number.
topic.model$train(1000)
topic.model$maximize(50)
doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
topic.words <- mallet.topic.words(topic.model, smoothed=T, normalized=T)
mallet.top.words(topic.model, topic.words[1,], 30)
topics.labels <- gsub("\\W", "_", mallet.topic.labels(topic.model, topic.words, 3))
topics.long.labels <- mallet.topic.labels(topic.model, topic.words, num.top.words=50)
doc.topics.frame <- data.frame(doc.topics)
#names(doc.topics.frame) <- paste("Topic", 1:n.topics, sep="")
names(doc.topics.frame) <- topics.labels
docs.and.topics <- cbind(documents, doc.topics.frame)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
Sys.setenv(JAVA_HOME='C:\Program Files\Java\jre1.8.0_101')
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
Sys.setenv(JAVA_HOME='C:/Program Files/Java/jre1.8.0_101')
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
Sys.setenv(JAVA_HOME='C:/Program Files/Java/jre1.8.0_101/bin')
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
Sys.setenv(JAVA_HOME='C:/Program Files/Java/jre1.8.0_101/bin')
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_101')
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
install.packages("rJava")
install.packages("rJava")
library (rJava)
library (rJava)
install.packages("rjava")
install.packages("rJava")
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
Sys.getenv("JAVA_HOME")
update.packages()
install.packages("rJava",type='source')
install.packages("rJava", type = "source")
install.packages("rJava", type = "source")
.jinit()
library(rJava)
.jinit()
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
#Import necessary libraries
library(dplyr)
library (rJava)
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library(ggplot2)
library(reshape2)
library(jsonlite)
#Set number of topics
n.topics <- 50
#Set working directory
setwd("C:\Users\a\Desktop\research17\autism-blogs\topicmodeling\mallet2")
#Import Json file to a data variable (requires formatting data once imported)
json_file <- "merged_file.json"
data <- fromJSON(json_file)
data <- bind_rows(data, .id = 'blog')
#Use rbind to create a documents variable from the data.frame
documents <- rbind(data.frame(blogid=data$blog, link=data$link, title=data$title, text=data$body,  stringsAsFactors=F))
#Use mallet as in sample code
mallet.instances <- mallet.import(documents$title, documents$text, "blog.stop", token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")
## Create a topic trainer object.
topic.model <- MalletLDA(num.topics=n.topics)
## Load our documents. We could also pass in the filename of a
##  saved instance list file that we build from the command-line tools.
topic.model$loadDocuments(mallet.instances)
## Get the vocabulary, and some statistics about word frequencies.
#vocabulary <- topic.model$getVocabulary()
#word.freqs <- mallet.word.freqs(topic.model)
## Optimize hyperparameters every 20 iterations,
##  after 50 burn-in iterations.
topic.model$setAlphaOptimization(20, 50)
## Now train a model.
##  We can specify the number of iterations. Here we'll use a large-ish round number.
topic.model$train(1000)
topic.model$maximize(50)
doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
topic.words <- mallet.topic.words(topic.model, smoothed=T, normalized=T)
mallet.top.words(topic.model, topic.words[1,], 30)
topics.labels <- gsub("\\W", "_", mallet.topic.labels(topic.model, topic.words, 3))
topics.long.labels <- mallet.topic.labels(topic.model, topic.words, num.top.words=50)
doc.topics.frame <- data.frame(doc.topics)
#names(doc.topics.frame) <- paste("Topic", 1:n.topics, sep="")
names(doc.topics.frame) <- topics.labels
docs.and.topics <- cbind(documents, doc.topics.frame)
#Import necessary libraries
library(dplyr)
library (rJava)
.jinit()
.jinit(parameters="-Xmx12g") #Give rJava enough memory
library(mallet)
library(ggplot2)
library(reshape2)
library(jsonlite)
#Set number of topics
n.topics <- 50
#Set working directory
setwd("C:/Users/a/Desktop/research17/autism-blogs/topicmodeling/mallet2")
#Import Json file to a data variable (requires formatting data once imported)
json_file <- "merged_file.json"
data <- fromJSON(json_file)
data <- bind_rows(data, .id = 'blog')
#Use rbind to create a documents variable from the data.frame
documents <- rbind(data.frame(blogid=data$blog, link=data$link, title=data$title, text=data$body,  stringsAsFactors=F))
#Use mallet as in sample code
mallet.instances <- mallet.import(documents$title, documents$text, "blog.stop", token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")
## Create a topic trainer object.
topic.model <- MalletLDA(num.topics=n.topics)
## Load our documents. We could also pass in the filename of a
##  saved instance list file that we build from the command-line tools.
topic.model$loadDocuments(mallet.instances)
## Get the vocabulary, and some statistics about word frequencies.
#vocabulary <- topic.model$getVocabulary()
#word.freqs <- mallet.word.freqs(topic.model)
## Optimize hyperparameters every 20 iterations,
##  after 50 burn-in iterations.
topic.model$setAlphaOptimization(20, 50)
## Now train a model.
##  We can specify the number of iterations. Here we'll use a large-ish round number.
topic.model$train(1000)
topic.model$maximize(50)
doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
topic.words <- mallet.topic.words(topic.model, smoothed=T, normalized=T)
mallet.top.words(topic.model, topic.words[1,], 30)
topics.labels <- gsub("\\W", "_", mallet.topic.labels(topic.model, topic.words, 3))
topics.long.labels <- mallet.topic.labels(topic.model, topic.words, num.top.words=50)
doc.topics.frame <- data.frame(doc.topics)
#names(doc.topics.frame) <- paste("Topic", 1:n.topics, sep="")
names(doc.topics.frame) <- topics.labels
docs.and.topics <- cbind(documents, doc.topics.frame)
save.image("C:/Users/a/Desktop/research17/autism-blogs/topicmodeling/mallet2/run5data.RData")
View(docs.and.topics)
save.image("C:/Users/a/Desktop/research17/autism-blogs/topicmodeling/mallet2/run5data.RData")
